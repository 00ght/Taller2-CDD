{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6539 - loss: 0.6230 - val_accuracy: 0.7391 - val_loss: 0.5029\n",
      "Epoch 2/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7204 - loss: 0.5437 - val_accuracy: 0.7391 - val_loss: 0.4950\n",
      "Epoch 3/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7567 - loss: 0.5127 - val_accuracy: 0.7329 - val_loss: 0.5014\n",
      "Epoch 4/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7702 - loss: 0.4915 - val_accuracy: 0.7536 - val_loss: 0.4906\n",
      "Epoch 5/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7749 - loss: 0.4504 - val_accuracy: 0.7453 - val_loss: 0.5000\n",
      "Epoch 6/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7926 - loss: 0.4288 - val_accuracy: 0.7371 - val_loss: 0.5201\n",
      "Epoch 7/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7977 - loss: 0.4160 - val_accuracy: 0.7391 - val_loss: 0.5276\n",
      "Epoch 8/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8347 - loss: 0.3778 - val_accuracy: 0.7350 - val_loss: 0.5397\n",
      "Epoch 9/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8451 - loss: 0.3685 - val_accuracy: 0.7371 - val_loss: 0.5665\n",
      "Epoch 10/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8289 - loss: 0.3630 - val_accuracy: 0.7226 - val_loss: 0.5713\n",
      "Epoch 11/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8764 - loss: 0.2842 - val_accuracy: 0.7350 - val_loss: 0.6433\n",
      "Epoch 12/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8742 - loss: 0.2970 - val_accuracy: 0.7019 - val_loss: 0.6487\n",
      "Epoch 13/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8993 - loss: 0.2454 - val_accuracy: 0.7143 - val_loss: 0.7283\n",
      "Epoch 14/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9149 - loss: 0.2233 - val_accuracy: 0.7122 - val_loss: 0.7497\n",
      "Epoch 15/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9054 - loss: 0.2157 - val_accuracy: 0.7226 - val_loss: 0.7571\n",
      "Epoch 16/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9181 - loss: 0.2096 - val_accuracy: 0.7184 - val_loss: 0.8367\n",
      "Epoch 17/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9199 - loss: 0.2044 - val_accuracy: 0.7143 - val_loss: 0.8615\n",
      "Epoch 18/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9395 - loss: 0.1618 - val_accuracy: 0.7226 - val_loss: 0.9089\n",
      "Epoch 19/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9233 - loss: 0.1789 - val_accuracy: 0.7205 - val_loss: 0.9134\n",
      "Loss: 0.5213\n",
      "Accuracy: 0.7285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = datos.iloc[:, :-1]\n",
    "y = datos.iloc[:, -1]\n",
    "\n",
    "# Drop the \"Id\" column\n",
    "X = X.drop('Id', axis=1)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipelines for numerical and categorical data\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Preprocess the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert target variable to numerical (binary encoding)\n",
    "y = pd.get_dummies(y, drop_first=True).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Build the neural network model with adjusted architecture and hyperparameters\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with adjusted learning rate\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best model overall: RandomForest\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Accuracy on test set: 0.7318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np  # Importar numpy para usar .ravel()\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'C': [1, 10, 100]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to perform grid search and return best model\n",
    "def find_best_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    # Convertir y_train y y_test a arrays 1D usando .ravel()\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return best_model, best_params, accuracy\n",
    "\n",
    "# Perform grid search for each model\n",
    "results = {}\n",
    "for model_name, config in models.items():\n",
    "    best_model, best_params, accuracy = find_best_model(config['model'], config['params'], X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'best_model': best_model,\n",
    "        'best_params': best_params,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "\n",
    "# Select the model with the highest accuracy\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['best_model']\n",
    "best_params = results[best_model_name]['best_params']\n",
    "best_accuracy = results[best_model_name]['accuracy']\n",
    "\n",
    "print(f\"Best model overall: {best_model_name}\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Accuracy on test set: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model selected: RandomForest\n",
      "Best parameters: {\"max_depth\": None, \"n_estimators\": 200}\n",
      "Accuracy on test set: 0.7318\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are already prepared and model is trained\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define and train the best model\n",
    "best_model = RandomForestClassifier(max_depth=None, n_estimators=200, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Best model selected: RandomForest')\n",
    "print(f'Best parameters: {{\"max_depth\": None, \"n_estimators\": 200}}')\n",
    "print(f'Accuracy on test set: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo \"clasificación_título.txt\" generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos de evaluación\n",
    "archivo_evaluacion = 'Taller_2_Titulacion_Evaluación.csv'\n",
    "datos_evaluacion = pd.read_csv(archivo_evaluacion, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Guardar los Ids para el archivo de salida\n",
    "ids_evaluacion = datos_evaluacion['Id']\n",
    "\n",
    "# Preprocesar datos de evaluación similar al conjunto de entrenamiento\n",
    "X_evaluacion = datos_evaluacion.drop('Id', axis=1)  # Eliminar columna 'Id'\n",
    "\n",
    "# Aplicar el preprocesamiento ya definido anteriormente\n",
    "X_evaluacion_processed = preprocessor.transform(X_evaluacion)\n",
    "\n",
    "# Realizar predicciones utilizando el mejor modelo seleccionado (RandomForest)\n",
    "predicciones_evaluacion = best_model.predict(X_evaluacion_processed)\n",
    "\n",
    "# Convertir predicciones a formato 'SÍ' o 'NO'\n",
    "predicciones_evaluacion_etiquetas = ['SÍ' if pred == 1 else 'NO' for pred in predicciones_evaluacion]\n",
    "\n",
    "# Crear DataFrame para el archivo de salida\n",
    "resultado_df = pd.DataFrame({'Id': ids_evaluacion, 'Predicción': predicciones_evaluacion_etiquetas})\n",
    "\n",
    "# Guardar resultados en archivo de texto\n",
    "archivo_salida = 'clasificación_título.txt'\n",
    "resultado_df.to_csv(archivo_salida, sep=';', index=False)\n",
    "\n",
    "print(f'Archivo \"{archivo_salida}\" generado exitosamente.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
