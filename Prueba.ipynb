{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 2: Aprendizaje Supervisado – Modelos de Clasificación\n",
    "Integrantes: Zada Riquelme y Vania Reyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el preprocesamiento de datos, llevamos a cabo una limpieza de columnas y rellenamos los datos perdidos con ceros, esta última decisión la tomamos al ser que la columna INS_1SEM e INS_2SEM proporciona información de las asignaturas que se tomaron por cada semestre cada alumno, lo que nos llevó a conjeturar que los promedios que se encontraban vacíos es porque el estudiante no los inscribió por lo que nos pareció más prudente reemplazarlos por ceros que por la media, la cual era otra de nuestras opciones.\n",
    "A continuación mencionamos las columnas que determinamos que no son relevantes para este objetivo del taller: ACTF_1SEM_R, ACTF_2SEM_R, descripcion_situacion_egreso_postulante, nombre_secretaria_admision, descripcion_jefe_familia, descripcion_nivel_educacion_padre, descripcion_nivel_educacion_madre, descipcion_tipo_organismo_trabajan_padre, descripcion_tipo_organismo_trabajan_madre, descripcion_ocupacion_principal_padre, descripcion_ocupacion_principal_madre, descripcion_rama_actividad_padre, descripcion_rama_actividad_madre, cuantos_trabajan_grupos_familiar, cuantos_estudian_grupo_familiar, cuantos_estudian_grupo_pre_basica, cuantos_estudian_grupo_media_1_3, cuantos_estudian_grupo_media_4, cuantos_estudian_grupo_otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se ha elegido la estrategia de validación cruzada K-fold, que consiste en dividir el conjunto de datos en 'k' particiones y entrenar el modelo en 'k-1' particiones, mientras se valida en la partición restante. Esta estrategia ayuda a reducir el riesgo de overfitting y a obtener una estimación más precisa del desempeño del modelo.\n",
    "\n",
    "En el código proporcionado, se ha implementado la validación cruzada K-fold con 'k' igual a 5. Se han llevado a cabo las siguientes acciones: se han cargado los datos desde un archivo CSV, se han seleccionado las columnas numéricas y categóricas, se han definido dos pipelines de preprocesamiento, se ha aplicado el transformador de columnas a los datos, se ha codificado la etiqueta y se han convertido los datos a float32. Luego, se ha definido una función para crear el modelo, se ha establecido el número de pliegues y se ha inicializado el generador de particiones KFold. Finalmente, se ha entrenado el modelo en cada pliegue y se ha calculado la precisión promedio en validación cruzada K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando fold 1/5...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6626 - loss: 0.6004 - val_accuracy: 0.7219 - val_loss: 0.5286\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7544 - loss: 0.5064 - val_accuracy: 0.7185 - val_loss: 0.5249\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7464 - loss: 0.4970 - val_accuracy: 0.7252 - val_loss: 0.5247\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7638 - loss: 0.4765 - val_accuracy: 0.7334 - val_loss: 0.5188\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7716 - loss: 0.4639 - val_accuracy: 0.7384 - val_loss: 0.5368\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7954 - loss: 0.4326 - val_accuracy: 0.7285 - val_loss: 0.5303\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8146 - loss: 0.4061 - val_accuracy: 0.7285 - val_loss: 0.5438\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8312 - loss: 0.3743 - val_accuracy: 0.7185 - val_loss: 0.5864\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8318 - loss: 0.3552 - val_accuracy: 0.7169 - val_loss: 0.6034\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8535 - loss: 0.3358 - val_accuracy: 0.7252 - val_loss: 0.5843\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8533 - loss: 0.3408 - val_accuracy: 0.7169 - val_loss: 0.6573\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8827 - loss: 0.2835 - val_accuracy: 0.7252 - val_loss: 0.7181\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8793 - loss: 0.2653 - val_accuracy: 0.7086 - val_loss: 0.6987\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9097 - loss: 0.2280 - val_accuracy: 0.7169 - val_loss: 0.7228\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9071 - loss: 0.2213 - val_accuracy: 0.7053 - val_loss: 0.8757\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9137 - loss: 0.2016 - val_accuracy: 0.6987 - val_loss: 0.8874\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9346 - loss: 0.1637 - val_accuracy: 0.7020 - val_loss: 0.8896\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9198 - loss: 0.1843 - val_accuracy: 0.7036 - val_loss: 0.9853\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9212 - loss: 0.1849 - val_accuracy: 0.6904 - val_loss: 1.0027\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9391 - loss: 0.1638 - val_accuracy: 0.6937 - val_loss: 1.0826\n",
      "Entrenando fold 2/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6572 - loss: 0.6106 - val_accuracy: 0.7517 - val_loss: 0.4989\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7219 - loss: 0.5369 - val_accuracy: 0.7384 - val_loss: 0.4936\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7296 - loss: 0.5022 - val_accuracy: 0.7649 - val_loss: 0.4869\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7475 - loss: 0.4970 - val_accuracy: 0.7583 - val_loss: 0.4916\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7908 - loss: 0.4425 - val_accuracy: 0.7682 - val_loss: 0.4835\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7901 - loss: 0.4398 - val_accuracy: 0.7434 - val_loss: 0.4899\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8172 - loss: 0.3980 - val_accuracy: 0.7467 - val_loss: 0.4957\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8236 - loss: 0.3808 - val_accuracy: 0.7533 - val_loss: 0.5221\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8275 - loss: 0.3661 - val_accuracy: 0.7732 - val_loss: 0.5184\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8646 - loss: 0.3300 - val_accuracy: 0.7517 - val_loss: 0.5344\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8460 - loss: 0.3187 - val_accuracy: 0.7368 - val_loss: 0.6270\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8797 - loss: 0.2848 - val_accuracy: 0.7583 - val_loss: 0.6165\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8843 - loss: 0.2660 - val_accuracy: 0.7583 - val_loss: 0.6041\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8865 - loss: 0.2501 - val_accuracy: 0.7368 - val_loss: 0.6766\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8927 - loss: 0.2388 - val_accuracy: 0.7417 - val_loss: 0.7057\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9234 - loss: 0.1813 - val_accuracy: 0.7268 - val_loss: 0.7414\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9184 - loss: 0.1980 - val_accuracy: 0.7434 - val_loss: 0.7437\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9374 - loss: 0.1694 - val_accuracy: 0.7318 - val_loss: 0.7797\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9368 - loss: 0.1562 - val_accuracy: 0.7434 - val_loss: 0.8061\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9381 - loss: 0.1545 - val_accuracy: 0.7500 - val_loss: 0.7480\n",
      "Epoch 21/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9418 - loss: 0.1439 - val_accuracy: 0.7334 - val_loss: 0.8647\n",
      "Epoch 22/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9465 - loss: 0.1385 - val_accuracy: 0.7566 - val_loss: 0.8752\n",
      "Epoch 23/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9658 - loss: 0.1012 - val_accuracy: 0.7417 - val_loss: 0.9715\n",
      "Epoch 24/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9513 - loss: 0.1288 - val_accuracy: 0.7169 - val_loss: 0.9937\n",
      "Entrenando fold 3/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6639 - loss: 0.5996 - val_accuracy: 0.6954 - val_loss: 0.5567\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7366 - loss: 0.5101 - val_accuracy: 0.7318 - val_loss: 0.5455\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7629 - loss: 0.4859 - val_accuracy: 0.7401 - val_loss: 0.5460\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7979 - loss: 0.4441 - val_accuracy: 0.7434 - val_loss: 0.5468\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7759 - loss: 0.4433 - val_accuracy: 0.7517 - val_loss: 0.5503\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8109 - loss: 0.4177 - val_accuracy: 0.7318 - val_loss: 0.5842\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8078 - loss: 0.4099 - val_accuracy: 0.7252 - val_loss: 0.5904\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8251 - loss: 0.3675 - val_accuracy: 0.7202 - val_loss: 0.6444\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8487 - loss: 0.3447 - val_accuracy: 0.7169 - val_loss: 0.6492\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8700 - loss: 0.2939 - val_accuracy: 0.7252 - val_loss: 0.6418\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8834 - loss: 0.2849 - val_accuracy: 0.7103 - val_loss: 0.6872\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8869 - loss: 0.2698 - val_accuracy: 0.7152 - val_loss: 0.7354\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8903 - loss: 0.2470 - val_accuracy: 0.7185 - val_loss: 0.8845\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8953 - loss: 0.2462 - val_accuracy: 0.7086 - val_loss: 0.8653\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9045 - loss: 0.2185 - val_accuracy: 0.7136 - val_loss: 0.8946\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9254 - loss: 0.1999 - val_accuracy: 0.7185 - val_loss: 0.9550\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9264 - loss: 0.1696 - val_accuracy: 0.7152 - val_loss: 1.0483\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9290 - loss: 0.1795 - val_accuracy: 0.7103 - val_loss: 1.0858\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9410 - loss: 0.1438 - val_accuracy: 0.7070 - val_loss: 1.1204\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9489 - loss: 0.1312 - val_accuracy: 0.7070 - val_loss: 1.1159\n",
      "Entrenando fold 4/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.6312 - loss: 0.6168 - val_accuracy: 0.7330 - val_loss: 0.5125\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7324 - loss: 0.5234 - val_accuracy: 0.7264 - val_loss: 0.5129\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7581 - loss: 0.4865 - val_accuracy: 0.7496 - val_loss: 0.4913\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7709 - loss: 0.4768 - val_accuracy: 0.7446 - val_loss: 0.5038\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7899 - loss: 0.4542 - val_accuracy: 0.7463 - val_loss: 0.5189\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8031 - loss: 0.4306 - val_accuracy: 0.7546 - val_loss: 0.5231\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8230 - loss: 0.3966 - val_accuracy: 0.7496 - val_loss: 0.5170\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8174 - loss: 0.3855 - val_accuracy: 0.7446 - val_loss: 0.5365\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8437 - loss: 0.3520 - val_accuracy: 0.7479 - val_loss: 0.5594\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8581 - loss: 0.3147 - val_accuracy: 0.7463 - val_loss: 0.5964\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8673 - loss: 0.3006 - val_accuracy: 0.7148 - val_loss: 0.6454\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8826 - loss: 0.2874 - val_accuracy: 0.7579 - val_loss: 0.6197\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8897 - loss: 0.2669 - val_accuracy: 0.7496 - val_loss: 0.6944\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8792 - loss: 0.2600 - val_accuracy: 0.7330 - val_loss: 0.6940\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9053 - loss: 0.2297 - val_accuracy: 0.7479 - val_loss: 0.7470\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9131 - loss: 0.2260 - val_accuracy: 0.7430 - val_loss: 0.7682\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9150 - loss: 0.2034 - val_accuracy: 0.7231 - val_loss: 0.8146\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9240 - loss: 0.1841 - val_accuracy: 0.7347 - val_loss: 0.8830\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9290 - loss: 0.1759 - val_accuracy: 0.7363 - val_loss: 0.9371\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9391 - loss: 0.1652 - val_accuracy: 0.7264 - val_loss: 0.8678\n",
      "Epoch 21/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9433 - loss: 0.1452 - val_accuracy: 0.7330 - val_loss: 0.9771\n",
      "Epoch 22/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9491 - loss: 0.1327 - val_accuracy: 0.7363 - val_loss: 1.0044\n",
      "Epoch 23/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9519 - loss: 0.1284 - val_accuracy: 0.7214 - val_loss: 1.0919\n",
      "Epoch 24/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9525 - loss: 0.1225 - val_accuracy: 0.7197 - val_loss: 1.0227\n",
      "Epoch 25/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9600 - loss: 0.1223 - val_accuracy: 0.7164 - val_loss: 1.1436\n",
      "Epoch 26/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9551 - loss: 0.1113 - val_accuracy: 0.7313 - val_loss: 1.1024\n",
      "Epoch 27/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9572 - loss: 0.1058 - val_accuracy: 0.7297 - val_loss: 1.0989\n",
      "Entrenando fold 5/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6499 - loss: 0.6125 - val_accuracy: 0.7297 - val_loss: 0.5199\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7348 - loss: 0.5299 - val_accuracy: 0.7479 - val_loss: 0.4963\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7612 - loss: 0.4982 - val_accuracy: 0.7463 - val_loss: 0.5010\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7698 - loss: 0.4769 - val_accuracy: 0.7430 - val_loss: 0.5005\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7964 - loss: 0.4361 - val_accuracy: 0.7446 - val_loss: 0.5054\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7870 - loss: 0.4601 - val_accuracy: 0.7529 - val_loss: 0.5048\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8133 - loss: 0.4093 - val_accuracy: 0.7347 - val_loss: 0.5603\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8387 - loss: 0.3707 - val_accuracy: 0.7280 - val_loss: 0.5425\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8401 - loss: 0.3442 - val_accuracy: 0.7231 - val_loss: 0.5615\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8627 - loss: 0.3102 - val_accuracy: 0.7181 - val_loss: 0.5739\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8630 - loss: 0.3109 - val_accuracy: 0.7214 - val_loss: 0.6038\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8819 - loss: 0.2803 - val_accuracy: 0.7347 - val_loss: 0.6135\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8955 - loss: 0.2644 - val_accuracy: 0.7048 - val_loss: 0.7262\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8961 - loss: 0.2501 - val_accuracy: 0.7048 - val_loss: 0.7407\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9079 - loss: 0.2137 - val_accuracy: 0.7131 - val_loss: 0.8043\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9225 - loss: 0.1875 - val_accuracy: 0.6799 - val_loss: 0.7881\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9196 - loss: 0.1957 - val_accuracy: 0.7048 - val_loss: 0.8203\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9316 - loss: 0.1721 - val_accuracy: 0.6882 - val_loss: 0.9253\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9442 - loss: 0.1515 - val_accuracy: 0.6700 - val_loss: 0.9314\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9388 - loss: 0.1472 - val_accuracy: 0.6932 - val_loss: 0.9357\n",
      "Epoch 21/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9535 - loss: 0.1242 - val_accuracy: 0.6833 - val_loss: 1.0337\n",
      "Precisión promedio en validación cruzada K-fold: 0.7061 ± 0.0164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "X = datos.iloc[:, :-1]\n",
    "y = datos.iloc[:, -1]\n",
    "X = X.drop('Id', axis=1)\n",
    "\n",
    "columnas_numericas = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "columnas_categoricas = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "pipeline_numerico = Pipeline([\n",
    "    ('imputador', SimpleImputer(strategy='median')),\n",
    "    ('escalador', StandardScaler())\n",
    "])\n",
    "\n",
    "pipeline_categorico = Pipeline([\n",
    "    ('imputador', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocesador = ColumnTransformer([\n",
    "    ('num', pipeline_numerico, columnas_numericas),\n",
    "    ('cat', pipeline_categorico, columnas_categoricas)\n",
    "])\n",
    "\n",
    "X_procesado = preprocesador.fit_transform(X)\n",
    "y = pd.get_dummies(y, drop_first=True).values\n",
    "X_procesado = X_procesado.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "def crear_modelo():\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(512, activation='relu', input_shape=(X_procesado.shape[1],)))\n",
    "    modelo.add(Dropout(0.5))\n",
    "    modelo.add(Dense(512, activation='relu'))\n",
    "    modelo.add(Dropout(0.5))\n",
    "    modelo.add(Dense(256, activation='relu'))\n",
    "    modelo.add(Dense(1, activation='sigmoid'))\n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for fold_index, (train_index, val_index) in enumerate(kf.split(X_procesado, y)):\n",
    "    print(f'Entrenando fold {fold_index + 1}/{num_folds}...')\n",
    "    \n",
    "    X_train, X_val = X_procesado[train_index], X_procesado[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    modelo = crear_modelo()\n",
    "    \n",
    "    parada_temprana = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "    \n",
    "    historia = modelo.fit(X_train, y_train, epochs=200, batch_size=64,\n",
    "                          validation_data=(X_val, y_val), callbacks=[parada_temprana], verbose=1)\n",
    "    \n",
    "    resultados.append(historia.history['val_accuracy'][-1])\n",
    "\n",
    "resultados = np.array(resultados)\n",
    "print(f'Precisión promedio en validación cruzada K-fold: {np.mean(resultados):.4f} ± {np.std(resultados):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifican dos tipos de modelos adecuados: Random Forest y SVM. Para cada modelo, se seleccionan al menos dos hiperparámetros que se pueden configurar para producir variantes del modelo. Luego, se ejecuta un proceso de búsqueda del mejor clasificador utilizando los dos tipos de modelos y con al menos dos parámetros o variantes por cada uno. Finalmente, se selecciona el modelo con mejor expectativa de ofrecer un buen resultado.\n",
    "\n",
    "En el código, se definen los modelos y sus parámetros, se ejecuta la búsqueda del mejor clasificador utilizando GridSearchCV y se selecciona el modelo con mejor precisión. Los resultados muestran que el modelo Random Forest con max_depth=None y n_estimators=200 es el mejor modelo, con una precisión del 73.18% en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Mejor modelo en general: RandomForest\n",
      "Mejores parámetros: {'max_depth': None, 'n_estimators': 200}\n",
      "Precisión en conjunto de prueba: 0.7318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "modelos = {\n",
    "    'RandomForest': {\n",
    "        'modelo': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'modelo': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'C': [1, 10, 100]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def encontrar_mejor_modelo(modelo, params, X_entrenamiento, y_entrenamiento, X_prueba, y_prueba):\n",
    "    y_entrenamiento = np.ravel(y_entrenamiento)\n",
    "    y_prueba = np.ravel(y_prueba)\n",
    "    \n",
    "    busqueda_grilla = GridSearchCV(estimator=modelo, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "    busqueda_grilla.fit(X_entrenamiento, y_entrenamiento)\n",
    "    \n",
    "    mejor_modelo = busqueda_grilla.best_estimator_\n",
    "    mejores_parametros = busqueda_grilla.best_params_\n",
    "    \n",
    "    y_pred = mejor_modelo.predict(X_prueba)\n",
    "    precision = accuracy_score(y_prueba, y_pred)\n",
    "    \n",
    "    return mejor_modelo, mejores_parametros, precision\n",
    "\n",
    "resultados = {}\n",
    "for nombre_modelo, config in modelos.items():\n",
    "    mejor_modelo, mejores_parametros, precision = encontrar_mejor_modelo(config['modelo'], config['params'], X_entrenamiento, y_entrenamiento, X_prueba, y_prueba)\n",
    "    \n",
    "    resultados[nombre_modelo] = {\n",
    "        'mejor_modelo': mejor_modelo,\n",
    "        'mejores_parametros': mejores_parametros,\n",
    "        'precision': precision\n",
    "    }\n",
    "    \n",
    "mejor_modelo_nombre = max(resultados, key=lambda x: resultados[x]['precision'])\n",
    "mejor_modelo = resultados[mejor_modelo_nombre]['mejor_modelo']\n",
    "mejores_parametros = resultados[mejor_modelo_nombre]['mejores_parametros']\n",
    "mejor_precision = resultados[mejor_modelo_nombre]['precision']\n",
    "\n",
    "print(f\"Mejor modelo en general: {mejor_modelo_nombre}\")\n",
    "print(f\"Mejores parámetros: {mejores_parametros}\")\n",
    "print(f\"Precisión en conjunto de prueba: {mejor_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo seleccionado: RandomForest\n",
      "Mejores parámetros: {\"max_depth\": None, \"n_estimators\": 200}\n",
      "Precisión en el conjunto de prueba: 0.7318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mejor_modelo = RandomForestClassifier(max_depth=None, n_estimators=200, random_state=42)\n",
    "mejor_modelo.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "y_pred = mejor_modelo.predict(X_prueba)\n",
    "precision = accuracy_score(y_prueba, y_pred)\n",
    "\n",
    "print(f'Mejor modelo seleccionado: RandomForest')\n",
    "print(f'Mejores parámetros: {{\"max_depth\": None, \"n_estimators\": 200}}')\n",
    "print(f'Precisión en el conjunto de prueba: {precision:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código proporcionado carga un conjunto de datos de evaluación desde un archivo CSV llamado Taller_2_Titulacion_Evaluación.csv y utiliza el mejor modelo encontrado en actividades previas para realizar la predicción sobre las 568 observaciones. Luego, se crea un archivo clasificación_título.txt que contiene el Id de cada registro y una etiqueta \"SÍ\" o \"NO\" que indica la predicción del modelo.\n",
    "\n",
    "El código sigue una estructura lógica y clara, desde la lectura de los datos hasta la escritura del archivo de salida. La utilización del mejor modelo encontrado en actividades previas garantiza que se esté utilizando el modelo más adecuado para realizar la predicción. El archivo de salida generado cumple con los requisitos de la actividad 4, sin encabezado y con la información solicitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo \"clasificación_título.txt\" generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archivo_evaluacion = 'Taller_2_Titulacion_Evaluación.csv'\n",
    "datos_evaluacion = pd.read_csv(archivo_evaluacion, encoding='latin-1', delimiter=';')\n",
    "\n",
    "ids_evaluacion = datos_evaluacion['Id']\n",
    "X_evaluacion = datos_evaluacion.drop('Id', axis=1)\n",
    "X_evaluacion_procesado = preprocesador.transform(X_evaluacion)\n",
    "\n",
    "predicciones_evaluacion = best_model.predict(X_evaluacion_procesado)\n",
    "predicciones_evaluacion_etiquetas = ['SÍ' if pred == 1 else 'NO' for pred in predicciones_evaluacion]\n",
    "resultado_df = pd.DataFrame({'Id': ids_evaluacion, 'Predicción': predicciones_evaluacion_etiquetas})\n",
    "\n",
    "archivo_salida = 'clasificación_título.txt'\n",
    "resultado_df.to_csv(archivo_salida, sep=';', index=False, header=None)\n",
    "\n",
    "print(f'Archivo \"{archivo_salida}\" generado exitosamente.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
