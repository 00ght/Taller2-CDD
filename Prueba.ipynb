{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 2: Aprendizaje Supervisado – Modelos de Clasificación\n",
    "Integrantes: Zada Riquelme y Vania Reyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el preprocesamiento de datos, llevamos a cabo una limpieza de columnas y rellenamos los datos perdidos con ceros, esta última decisión la tomamos al ser que la columna INS_1SEM e INS_2SEM proporciona información de las asignaturas que se tomaron por cada semestre cada alumno, lo que nos llevó a conjeturar que los promedios que se encontraban vacíos es porque el estudiante no los inscribió por lo que nos pareció más prudente reemplazarlos por ceros que por la media, la cual era otra de nuestras opciones.\n",
    "A continuación mencionamos las columnas que determinamos que no son relevantes para este objetivo del taller: ACTF_1SEM_R, ACTF_2SEM_R, descripcion_situacion_egreso_postulante, nombre_secretaria_admision, descripcion_jefe_familia, descripcion_nivel_educacion_padre, descripcion_nivel_educacion_madre, descipcion_tipo_organismo_trabajan_padre, descripcion_tipo_organismo_trabajan_madre, descripcion_ocupacion_principal_padre, descripcion_ocupacion_principal_madre, descripcion_rama_actividad_padre, descripcion_rama_actividad_madre, cuantos_trabajan_grupos_familiar, cuantos_estudian_grupo_familiar, cuantos_estudian_grupo_pre_basica, cuantos_estudian_grupo_media_1_3, cuantos_estudian_grupo_media_4, cuantos_estudian_grupo_otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando fold 1/5...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6534 - loss: 0.6033 - val_accuracy: 0.7070 - val_loss: 0.5454\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7236 - loss: 0.5324 - val_accuracy: 0.7252 - val_loss: 0.5238\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7554 - loss: 0.5028 - val_accuracy: 0.7169 - val_loss: 0.5388\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7619 - loss: 0.4931 - val_accuracy: 0.7550 - val_loss: 0.5158\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7900 - loss: 0.4600 - val_accuracy: 0.7401 - val_loss: 0.5183\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8102 - loss: 0.4264 - val_accuracy: 0.7202 - val_loss: 0.5347\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8011 - loss: 0.4193 - val_accuracy: 0.7268 - val_loss: 0.5401\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8055 - loss: 0.4052 - val_accuracy: 0.7020 - val_loss: 0.5490\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8273 - loss: 0.3657 - val_accuracy: 0.7119 - val_loss: 0.5723\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8617 - loss: 0.3232 - val_accuracy: 0.6954 - val_loss: 0.5992\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8659 - loss: 0.3138 - val_accuracy: 0.6970 - val_loss: 0.6422\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8724 - loss: 0.2899 - val_accuracy: 0.7086 - val_loss: 0.6469\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8871 - loss: 0.2670 - val_accuracy: 0.6987 - val_loss: 0.6948\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8996 - loss: 0.2496 - val_accuracy: 0.6937 - val_loss: 0.7468\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8991 - loss: 0.2311 - val_accuracy: 0.6937 - val_loss: 0.8041\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9227 - loss: 0.1955 - val_accuracy: 0.7169 - val_loss: 0.8627\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9253 - loss: 0.1864 - val_accuracy: 0.7003 - val_loss: 0.7493\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9314 - loss: 0.1729 - val_accuracy: 0.7053 - val_loss: 0.9136\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9320 - loss: 0.1601 - val_accuracy: 0.6821 - val_loss: 0.9889\n",
      "Entrenando fold 2/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6591 - loss: 0.6088 - val_accuracy: 0.7566 - val_loss: 0.5082\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7225 - loss: 0.5286 - val_accuracy: 0.7517 - val_loss: 0.4987\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7438 - loss: 0.5097 - val_accuracy: 0.7417 - val_loss: 0.5077\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7583 - loss: 0.4748 - val_accuracy: 0.7583 - val_loss: 0.4891\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7706 - loss: 0.4697 - val_accuracy: 0.7450 - val_loss: 0.4931\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7852 - loss: 0.4496 - val_accuracy: 0.7632 - val_loss: 0.4893\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7988 - loss: 0.4283 - val_accuracy: 0.7483 - val_loss: 0.5072\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8313 - loss: 0.3778 - val_accuracy: 0.7483 - val_loss: 0.5334\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8147 - loss: 0.3821 - val_accuracy: 0.7500 - val_loss: 0.5388\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8468 - loss: 0.3433 - val_accuracy: 0.7517 - val_loss: 0.5646\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8624 - loss: 0.3134 - val_accuracy: 0.7666 - val_loss: 0.5778\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8886 - loss: 0.2686 - val_accuracy: 0.7483 - val_loss: 0.6027\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9001 - loss: 0.2418 - val_accuracy: 0.7384 - val_loss: 0.6694\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9107 - loss: 0.2199 - val_accuracy: 0.7401 - val_loss: 0.7323\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9152 - loss: 0.2117 - val_accuracy: 0.7533 - val_loss: 0.6883\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9137 - loss: 0.2057 - val_accuracy: 0.7368 - val_loss: 0.7491\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9186 - loss: 0.1833 - val_accuracy: 0.7301 - val_loss: 0.7893\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9291 - loss: 0.1710 - val_accuracy: 0.7351 - val_loss: 0.7997\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.1613 - val_accuracy: 0.7384 - val_loss: 0.8388\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9484 - loss: 0.1286 - val_accuracy: 0.7351 - val_loss: 0.8975\n",
      "Epoch 21/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9438 - loss: 0.1227 - val_accuracy: 0.7252 - val_loss: 0.9360\n",
      "Epoch 22/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9481 - loss: 0.1197 - val_accuracy: 0.7235 - val_loss: 1.0453\n",
      "Epoch 23/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9455 - loss: 0.1363 - val_accuracy: 0.7351 - val_loss: 0.9523\n",
      "Epoch 24/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9550 - loss: 0.1191 - val_accuracy: 0.7152 - val_loss: 0.8923\n",
      "Epoch 25/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9540 - loss: 0.1190 - val_accuracy: 0.7434 - val_loss: 0.9825\n",
      "Epoch 26/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9654 - loss: 0.1007 - val_accuracy: 0.7219 - val_loss: 1.0639\n",
      "Entrenando fold 3/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6501 - loss: 0.5915 - val_accuracy: 0.7252 - val_loss: 0.5507\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7384 - loss: 0.5119 - val_accuracy: 0.7235 - val_loss: 0.5573\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7589 - loss: 0.4892 - val_accuracy: 0.7384 - val_loss: 0.5478\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7682 - loss: 0.4610 - val_accuracy: 0.7450 - val_loss: 0.5513\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7934 - loss: 0.4312 - val_accuracy: 0.7185 - val_loss: 0.5900\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8186 - loss: 0.3984 - val_accuracy: 0.7368 - val_loss: 0.5938\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8198 - loss: 0.3815 - val_accuracy: 0.7268 - val_loss: 0.6422\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8370 - loss: 0.3627 - val_accuracy: 0.7219 - val_loss: 0.6198\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8535 - loss: 0.3300 - val_accuracy: 0.7086 - val_loss: 0.6933\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8660 - loss: 0.3089 - val_accuracy: 0.6970 - val_loss: 0.6935\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8775 - loss: 0.2838 - val_accuracy: 0.7086 - val_loss: 0.7571\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8730 - loss: 0.2891 - val_accuracy: 0.6904 - val_loss: 0.7670\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9023 - loss: 0.2409 - val_accuracy: 0.7003 - val_loss: 0.8582\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8918 - loss: 0.2507 - val_accuracy: 0.6954 - val_loss: 0.8566\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9163 - loss: 0.2021 - val_accuracy: 0.6821 - val_loss: 0.9872\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9174 - loss: 0.2067 - val_accuracy: 0.7020 - val_loss: 0.9563\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9292 - loss: 0.1768 - val_accuracy: 0.6772 - val_loss: 1.1079\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9314 - loss: 0.1714 - val_accuracy: 0.6921 - val_loss: 1.1192\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9416 - loss: 0.1468 - val_accuracy: 0.6705 - val_loss: 1.2415\n",
      "Entrenando fold 4/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6694 - loss: 0.6000 - val_accuracy: 0.7181 - val_loss: 0.5339\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7377 - loss: 0.5216 - val_accuracy: 0.7330 - val_loss: 0.5129\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7439 - loss: 0.5012 - val_accuracy: 0.7280 - val_loss: 0.5084\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7720 - loss: 0.4703 - val_accuracy: 0.7380 - val_loss: 0.5142\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7916 - loss: 0.4675 - val_accuracy: 0.7529 - val_loss: 0.4976\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7995 - loss: 0.4328 - val_accuracy: 0.7446 - val_loss: 0.5172\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8146 - loss: 0.4011 - val_accuracy: 0.7380 - val_loss: 0.5309\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8255 - loss: 0.3872 - val_accuracy: 0.7396 - val_loss: 0.5488\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8339 - loss: 0.3701 - val_accuracy: 0.7347 - val_loss: 0.5414\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8463 - loss: 0.3399 - val_accuracy: 0.7396 - val_loss: 0.5651\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8602 - loss: 0.2977 - val_accuracy: 0.7363 - val_loss: 0.5973\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8845 - loss: 0.2839 - val_accuracy: 0.7264 - val_loss: 0.6139\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8903 - loss: 0.2614 - val_accuracy: 0.7247 - val_loss: 0.6740\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9050 - loss: 0.2286 - val_accuracy: 0.7446 - val_loss: 0.6967\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9059 - loss: 0.2187 - val_accuracy: 0.7380 - val_loss: 0.7369\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9174 - loss: 0.1920 - val_accuracy: 0.7164 - val_loss: 0.8541\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9241 - loss: 0.1903 - val_accuracy: 0.7098 - val_loss: 0.8012\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9242 - loss: 0.1847 - val_accuracy: 0.7148 - val_loss: 0.8636\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9284 - loss: 0.1709 - val_accuracy: 0.7048 - val_loss: 0.8970\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9364 - loss: 0.1571 - val_accuracy: 0.7148 - val_loss: 0.9497\n",
      "Entrenando fold 5/5...\n",
      "Epoch 1/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.6358 - loss: 0.6130 - val_accuracy: 0.7413 - val_loss: 0.4996\n",
      "Epoch 2/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7362 - loss: 0.5246 - val_accuracy: 0.7413 - val_loss: 0.4924\n",
      "Epoch 3/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7660 - loss: 0.4906 - val_accuracy: 0.7347 - val_loss: 0.5120\n",
      "Epoch 4/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7772 - loss: 0.4675 - val_accuracy: 0.7280 - val_loss: 0.4901\n",
      "Epoch 5/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7715 - loss: 0.4679 - val_accuracy: 0.7496 - val_loss: 0.5012\n",
      "Epoch 6/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8020 - loss: 0.4177 - val_accuracy: 0.7264 - val_loss: 0.5302\n",
      "Epoch 7/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8031 - loss: 0.4170 - val_accuracy: 0.7313 - val_loss: 0.5174\n",
      "Epoch 8/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8224 - loss: 0.4054 - val_accuracy: 0.7280 - val_loss: 0.5756\n",
      "Epoch 9/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8339 - loss: 0.3661 - val_accuracy: 0.7280 - val_loss: 0.5549\n",
      "Epoch 10/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8464 - loss: 0.3447 - val_accuracy: 0.7032 - val_loss: 0.6373\n",
      "Epoch 11/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8567 - loss: 0.3208 - val_accuracy: 0.7032 - val_loss: 0.6696\n",
      "Epoch 12/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8709 - loss: 0.2935 - val_accuracy: 0.7081 - val_loss: 0.6528\n",
      "Epoch 13/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8991 - loss: 0.2679 - val_accuracy: 0.7081 - val_loss: 0.6803\n",
      "Epoch 14/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9036 - loss: 0.2544 - val_accuracy: 0.7131 - val_loss: 0.7870\n",
      "Epoch 15/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9032 - loss: 0.2218 - val_accuracy: 0.6949 - val_loss: 0.7377\n",
      "Epoch 16/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9151 - loss: 0.2043 - val_accuracy: 0.6932 - val_loss: 0.8166\n",
      "Epoch 17/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9307 - loss: 0.1789 - val_accuracy: 0.6915 - val_loss: 0.8558\n",
      "Epoch 18/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9314 - loss: 0.1695 - val_accuracy: 0.6982 - val_loss: 0.8882\n",
      "Epoch 19/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9459 - loss: 0.1483 - val_accuracy: 0.6915 - val_loss: 0.9305\n",
      "Epoch 20/200\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9285 - loss: 0.1646 - val_accuracy: 0.7181 - val_loss: 0.9235\n",
      "Precisión promedio en validación cruzada K-fold: 0.7015 ± 0.0210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "X = datos.iloc[:, :-1]\n",
    "y = datos.iloc[:, -1]\n",
    "X = X.drop('Id', axis=1)\n",
    "\n",
    "columnas_numericas = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "columnas_categoricas = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "pipeline_numerico = Pipeline([\n",
    "    ('imputador', SimpleImputer(strategy='median')),\n",
    "    ('escalador', StandardScaler())\n",
    "])\n",
    "\n",
    "pipeline_categorico = Pipeline([\n",
    "    ('imputador', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocesador = ColumnTransformer([\n",
    "    ('num', pipeline_numerico, columnas_numericas),\n",
    "    ('cat', pipeline_categorico, columnas_categoricas)\n",
    "])\n",
    "\n",
    "X_procesado = preprocesador.fit_transform(X)\n",
    "y = pd.get_dummies(y, drop_first=True).values\n",
    "X_procesado = X_procesado.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "def crear_modelo():\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Dense(512, activation='relu', input_shape=(X_procesado.shape[1],)))\n",
    "    modelo.add(Dropout(0.5))\n",
    "    modelo.add(Dense(512, activation='relu'))\n",
    "    modelo.add(Dropout(0.5))\n",
    "    modelo.add(Dense(256, activation='relu'))\n",
    "    modelo.add(Dense(1, activation='sigmoid'))\n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for fold_index, (train_index, val_index) in enumerate(kf.split(X_procesado, y)):\n",
    "    print(f'Entrenando fold {fold_index + 1}/{num_folds}...')\n",
    "    \n",
    "    X_train, X_val = X_procesado[train_index], X_procesado[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    modelo = crear_modelo()\n",
    "    \n",
    "    parada_temprana = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "    \n",
    "    historia = modelo.fit(X_train, y_train, epochs=200, batch_size=64,\n",
    "                          validation_data=(X_val, y_val), callbacks=[parada_temprana], verbose=1)\n",
    "    \n",
    "    resultados.append(historia.history['val_accuracy'][-1])\n",
    "\n",
    "resultados = np.array(resultados)\n",
    "print(f'Precisión promedio en validación cruzada K-fold: {np.mean(resultados):.4f} ± {np.std(resultados):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best model overall: RandomForest\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Accuracy on test set: 0.7318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np  # Importar numpy para usar .ravel()\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'C': [1, 10, 100]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to perform grid search and return best model\n",
    "def find_best_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    # Convertir y_train y y_test a arrays 1D usando .ravel()\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return best_model, best_params, accuracy\n",
    "\n",
    "# Perform grid search for each model\n",
    "results = {}\n",
    "for model_name, config in models.items():\n",
    "    best_model, best_params, accuracy = find_best_model(config['model'], config['params'], X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'best_model': best_model,\n",
    "        'best_params': best_params,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "\n",
    "# Select the model with the highest accuracy\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['best_model']\n",
    "best_params = results[best_model_name]['best_params']\n",
    "best_accuracy = results[best_model_name]['accuracy']\n",
    "\n",
    "print(f\"Best model overall: {best_model_name}\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Accuracy on test set: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model selected: RandomForest\n",
      "Best parameters: {\"max_depth\": None, \"n_estimators\": 200}\n",
      "Accuracy on test set: 0.7318\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are already prepared and model is trained\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define and train the best model\n",
    "best_model = RandomForestClassifier(max_depth=None, n_estimators=200, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Best model selected: RandomForest')\n",
    "print(f'Best parameters: {{\"max_depth\": None, \"n_estimators\": 200}}')\n",
    "print(f'Accuracy on test set: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo \"clasificación_título.txt\" generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos de evaluación\n",
    "archivo_evaluacion = 'Taller_2_Titulacion_Evaluación.csv'\n",
    "datos_evaluacion = pd.read_csv(archivo_evaluacion, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Guardar los Ids para el archivo de salida\n",
    "ids_evaluacion = datos_evaluacion['Id']\n",
    "\n",
    "# Preprocesar datos de evaluación similar al conjunto de entrenamiento\n",
    "X_evaluacion = datos_evaluacion.drop('Id', axis=1)  # Eliminar columna 'Id'\n",
    "\n",
    "# Aplicar el preprocesamiento ya definido anteriormente\n",
    "X_evaluacion_processed = preprocessor.transform(X_evaluacion)\n",
    "\n",
    "# Realizar predicciones utilizando el mejor modelo seleccionado (RandomForest)\n",
    "predicciones_evaluacion = best_model.predict(X_evaluacion_processed)\n",
    "\n",
    "# Convertir predicciones a formato 'SÍ' o 'NO'\n",
    "predicciones_evaluacion_etiquetas = ['SÍ' if pred == 1 else 'NO' for pred in predicciones_evaluacion]\n",
    "\n",
    "# Crear DataFrame para el archivo de salida\n",
    "resultado_df = pd.DataFrame({'Id': ids_evaluacion, 'Predicción': predicciones_evaluacion_etiquetas})\n",
    "\n",
    "# Guardar resultados en archivo de texto\n",
    "archivo_salida = 'clasificación_título.txt'\n",
    "resultado_df.to_csv(archivo_salida, sep=';', index=False)\n",
    "\n",
    "print(f'Archivo \"{archivo_salida}\" generado exitosamente.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
