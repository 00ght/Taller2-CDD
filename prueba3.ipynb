{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 2: Aprendizaje Supervisado – Modelos de Clasificación\n",
    "Integrantes: Zada Riquelme y Vania Reyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1\n",
    "Para el preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Ver el número de valores faltantes por columna\n",
    "valores_faltantes = datos.isnull().sum()\n",
    "\n",
    "# Identificar las columnas categóricas\n",
    "columnas_categoricas = datos.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Codificar las variables categóricas\n",
    "datos_codificados = pd.get_dummies(datos, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "# Normalizar las características numéricas\n",
    "columnas_numericas = datos_codificados.select_dtypes(include=['float64', 'int64']).columns\n",
    "escalador = StandardScaler()\n",
    "datos_codificados[columnas_numericas] = escalador.fit_transform(datos_codificados[columnas_numericas])\n",
    "\n",
    "# Separar características y la variable objetivo\n",
    "X = datos_codificados.drop(columns=['Rotulo_Titulo_SI'])\n",
    "y = datos_codificados['Rotulo_Titulo_SI']\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba (solo para referencia)\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices de entrenamiento: [   1    2    3 ... 2411 2412 2413]\n",
      "Índices de validación: [   0    4    8   11   16   18   19   29   31   37   44   45   65   68\n",
      "   69   74   75   81   85   89   90   98  100  101  105  106  108  123\n",
      "  127  128  131  137  149  150  158  162  171  181  184  200  201  205\n",
      "  207  208  213  214  224  225  228  234  236  243  252  255  256  258\n",
      "  261  268  280  282  289  290  293  296  299  303  310  317  319  321\n",
      "  327  331  342  346  348  349  350  358  364  370  371  387  394  404\n",
      "  406  412  413  417  419  421  432  442  459  463  464  477  481  483\n",
      "  485  487  503  512  515  523  526  532  534  541  563  565  567  571\n",
      "  572  576  578  579  581  588  589  607  611  612  614  621  626  627\n",
      "  629  632  637  641  646  648  651  652  669  677  680  684  686  688\n",
      "  694  698  711  716  727  731  736  739  742  743  750  752  753  759\n",
      "  768  770  791  794  801  803  806  819  826  829  835  838  841  847\n",
      "  854  857  859  861  876  877  878  882  885  886  894  895  897  899\n",
      "  905  921  923  925  933  940  941  943  951  960  966  970  972  974\n",
      "  976 1002 1004 1006 1007 1012 1015 1018 1031 1036 1046 1047 1048 1050\n",
      " 1052 1053 1062 1068 1073 1076 1077 1081 1086 1093 1099 1108 1113 1114\n",
      " 1125 1130 1141 1144 1151 1153 1157 1165 1169 1170 1172 1177 1198 1204\n",
      " 1206 1208 1210 1212 1218 1222 1225 1239 1244 1247 1249 1251 1253 1261\n",
      " 1266 1267 1271 1272 1273 1275 1276 1277 1279 1281 1283 1286 1287 1288\n",
      " 1291 1292 1295 1307 1308 1310 1326 1338 1339 1344 1346 1349 1351 1355\n",
      " 1362 1373 1391 1395 1399 1409 1419 1422 1427 1436 1441 1443 1458 1461\n",
      " 1462 1464 1472 1485 1492 1498 1502 1509 1510 1513 1514 1518 1519 1535\n",
      " 1537 1543 1545 1550 1556 1557 1558 1563 1564 1566 1567 1570 1572 1578\n",
      " 1591 1595 1601 1613 1618 1619 1627 1630 1631 1633 1634 1641 1659 1664\n",
      " 1666 1673 1686 1687 1690 1696 1702 1707 1710 1712 1713 1714 1726 1734\n",
      " 1736 1738 1750 1759 1760 1764 1771 1783 1784 1792 1793 1794 1795 1800\n",
      " 1807 1818 1822 1825 1826 1829 1830 1835 1839 1860 1862 1863 1864 1871\n",
      " 1872 1874 1894 1896 1901 1919 1924 1925 1929 1931 1945 1951 1953 1955\n",
      " 1959 1979 1980 1982 1988 1990 1995 1999 2002 2003 2006 2016 2017 2038\n",
      " 2039 2043 2049 2070 2077 2083 2087 2091 2098 2106 2107 2111 2113 2120\n",
      " 2122 2123 2134 2138 2140 2141 2143 2150 2157 2159 2160 2171 2175 2185\n",
      " 2188 2193 2200 2204 2207 2218 2223 2225 2228 2234 2236 2244 2250 2251\n",
      " 2253 2255 2256 2262 2264 2267 2269 2273 2275 2291 2293 2294 2295 2313\n",
      " 2314 2320 2327 2330 2337 2339 2342 2345 2349 2353 2356 2368 2371 2372\n",
      " 2382 2398 2401 2402 2404 2407 2409]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Crear el clasificador RandomForest\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir el número de folds para k-Fold CV\n",
    "k = 5\n",
    "\n",
    "# Realizar validación cruzada k-Fold estratificada\n",
    "validacion_cruzada = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Para almacenar los índices de entrenamiento y validación de cada pliegue\n",
    "indices_pliegues = []\n",
    "\n",
    "# Generar los índices para cada pliegue\n",
    "for indice_entrenamiento, indice_validacion in validacion_cruzada.split(X_entrenamiento, y_entrenamiento):\n",
    "    indices_pliegues.append((indice_entrenamiento, indice_validacion))\n",
    "\n",
    "# Imprimir los índices de entrenamiento y validación del primer pliegue como ejemplo\n",
    "indice_entrenamiento, indice_validacion = indices_pliegues[0]\n",
    "print(\"Índices de entrenamiento:\", indice_entrenamiento)\n",
    "print(\"Índices de validación:\", indice_validacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo RandomForestClassifier:\n",
      "RandomForestClassifier(max_depth=20, n_estimators=150, random_state=42)\n",
      "Puntuación de precisión en validación cruzada: 0.7580904272226661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "# Definir el clasificador RandomForest\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# Definir la estrategia de validación cruzada k-Fold estratificada\n",
    "k = 5\n",
    "stratified_kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizar búsqueda exhaustiva de parámetros con validación cruzada estratificada\n",
    "grid_search_rf = GridSearchCV(rf_clf, param_grid_rf, cv=stratified_kfold, scoring='accuracy')\n",
    "grid_search_rf.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "# Obtener el mejor modelo y su puntaje\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "best_rf_score = grid_search_rf.best_score_\n",
    "\n",
    "print(\"Mejor modelo RandomForestClassifier:\")\n",
    "print(best_rf_model)\n",
    "print(f\"Puntuación de precisión en validación cruzada: {best_rf_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el clasificador\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid_svm = {\n",
    "    'C': [1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Realizar búsqueda exhaustiva de parámetros\n",
    "grid_search_svm = GridSearchCV(svm_clf, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "# Obtener el mejor modelo y su puntaje\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "best_svm_score = grid_search_svm.best_score_\n",
    "\n",
    "print(\"Mejor modelo SVM:\")\n",
    "print(best_svm_model)\n",
    "print(f\"Puntuación de precisión en validación cruzada: {best_svm_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m datos_evaluacion \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(archivo_evaluacion, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Suponiendo que `preprocessor` es el objeto que utilizaste para preprocesar `X_train`\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# y `best_rf_model` es el mejor modelo RandomForestClassifier seleccionado\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Preprocesar datos de evaluación similar al conjunto de entrenamiento\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m X_evaluacion_processed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(datos_evaluacion)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Realizar predicciones sobre el conjunto de evaluación usando el mejor modelo encontrado\u001b[39;00m\n\u001b[0;32m     15\u001b[0m y_pred_eval \u001b[38;5;241m=\u001b[39m best_rf_model\u001b[38;5;241m.\u001b[39mpredict(X_evaluacion_processed)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar el conjunto de datos de evaluación\n",
    "archivo_evaluacion = 'Taller_2_Titulacion_Evaluación.csv'\n",
    "datos_evaluacion = pd.read_csv(archivo_evaluacion, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Suponiendo que `preprocessor` es el objeto que utilizaste para preprocesar `X_train`\n",
    "# y `best_rf_model` es el mejor modelo RandomForestClassifier seleccionado\n",
    "\n",
    "# Preprocesar datos de evaluación similar al conjunto de entrenamiento\n",
    "X_evaluacion_processed = preprocessor.transform(datos_evaluacion)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de evaluación usando el mejor modelo encontrado\n",
    "y_pred_eval = best_rf_model.predict(X_evaluacion_processed)\n",
    "\n",
    "# Convertir predicciones a formato 'SÍ' o 'NO'\n",
    "predicciones_evaluacion_etiquetas = ['SÍ' if pred == 1 else 'NO' for pred in y_pred_eval]\n",
    "\n",
    "# Crear DataFrame para el archivo de salida\n",
    "resultado_df = pd.DataFrame({'Id': datos_evaluacion['Id'], 'Predicción': predicciones_evaluacion_etiquetas})\n",
    "\n",
    "# Guardar resultados en archivo de texto\n",
    "archivo_salida = 'clasificación_título.txt'\n",
    "resultado_df.to_csv(archivo_salida, sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "print(f'Archivo \"{archivo_salida}\" generado exitosamente.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Precisión del mejor modelo en CV: 0.761385015850107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir parámetros para la búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros en el conjunto de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo seleccionado\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Mostrar la precisión del mejor modelo en el conjunto de validación cruzada\n",
    "print(\"Precisión del mejor modelo en CV:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 46 features, but RandomForestClassifier is expecting 493 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m X_evaluacion_processed \u001b[38;5;241m=\u001b[39m X_evaluacion_numerico_scaled  \u001b[38;5;66;03m# Ajusta según tus datos y preprocesador\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Realizar predicciones sobre el conjunto de evaluación usando el mejor modelo encontrado\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m y_pred_eval \u001b[38;5;241m=\u001b[39m \u001b[43mbest_rf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_evaluacion_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Convertir predicciones a formato 'SÍ' o 'NO'\u001b[39;00m\n\u001b[0;32m     26\u001b[0m predicciones_evaluacion_etiquetas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSÍ\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNO\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m y_pred_eval]\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 46 features, but RandomForestClassifier is expecting 493 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler  # Importa el preprocesador adecuado según tu caso\n",
    "\n",
    "# Cargar los datos de evaluación\n",
    "archivo_evaluacion = 'Taller_2_Titulacion_Evaluación.csv'\n",
    "datos_evaluacion = pd.read_csv(archivo_evaluacion, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Asumiendo que `preprocessor` es el objeto que utilizaste para preprocesar `X_train`\n",
    "# y `best_rf_model` es el mejor modelo RandomForestClassifier seleccionado\n",
    "\n",
    "# Preprocesar datos de evaluación similar al conjunto de entrenamiento\n",
    "# Ajusta según tus datos y preprocesador utilizado\n",
    "scaler = StandardScaler()  # Ejemplo de preprocesador, ajusta según tu caso\n",
    "X_evaluacion_numerico = datos_evaluacion.select_dtypes(include=['int64', 'float64'])  # Selecciona características numéricas\n",
    "X_evaluacion_numerico_scaled = scaler.fit_transform(X_evaluacion_numerico)  # Ajusta y transforma según tu preprocesador\n",
    "\n",
    "# Asume que aquí también se manejan las variables categóricas si es necesario\n",
    "\n",
    "# Concatenar características preprocesadas\n",
    "X_evaluacion_processed = X_evaluacion_numerico_scaled  # Ajusta según tus datos y preprocesador\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de evaluación usando el mejor modelo encontrado\n",
    "y_pred_eval = best_rf_model.predict(X_evaluacion_processed)\n",
    "\n",
    "# Convertir predicciones a formato 'SÍ' o 'NO'\n",
    "predicciones_evaluacion_etiquetas = ['SÍ' if pred == 1 else 'NO' for pred in y_pred_eval]\n",
    "\n",
    "# Crear DataFrame para el archivo de salida\n",
    "resultado_df = pd.DataFrame({'Id': datos_evaluacion['Id'], 'Predicción': predicciones_evaluacion_etiquetas})\n",
    "\n",
    "# Guardar resultados en archivo de texto\n",
    "archivo_salida = 'clasificación_título.txt'\n",
    "resultado_df.to_csv(archivo_salida, sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "print(f'Archivo \"{archivo_salida}\" generado exitosamente.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
