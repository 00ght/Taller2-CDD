{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna:\n",
      "Id                                                     0\n",
      "MAT_1SEM_PROM                                          0\n",
      "FIS_1SEM_PROM                                          0\n",
      "ING_1SEM_PROM                                          0\n",
      "ACTF_1SEM_A                                            0\n",
      "OTRANS_1SEM_A                                          0\n",
      "OTRANS_1SEM_R                                          0\n",
      "OTRANS_1SEM_PROM                                       0\n",
      "ESP_1SEM_A                                             0\n",
      "ESP_1SEM_R                                             0\n",
      "ESP_1SEM_PROM                                          0\n",
      "INS_1SEM                                               0\n",
      "PROM_1SEM                                              0\n",
      "MAT_2SEM_PROM                                          0\n",
      "FIS_2SEM_PROM                                          0\n",
      "ING_2SEM_PROM                                          0\n",
      "ACTF_2SEM_A                                            0\n",
      "OTRANS_2SEM_A                                          0\n",
      "OTRANS_2SEM_R                                          0\n",
      "OTRANS_2SEM_PROM                                       0\n",
      "ESP_2SEM_A                                             0\n",
      "ESP_2SEM_R                                             0\n",
      "ESP_2SEM_PROM                                          0\n",
      "INS_2SEM                                               0\n",
      "PROM_2SEM                                              0\n",
      "INSC_AnO                                               0\n",
      "PROM_AnO                                               0\n",
      "GENERO                                                 0\n",
      "NOM_CARRERA                                            0\n",
      "TIPO_CARRERA                                           0\n",
      "nombre_nacionalidad                                    0\n",
      "nombre_comuna_EM                                       0\n",
      "nombre_provincia_EM                                    0\n",
      "nombre_region_EM                                       0\n",
      "nombre_grupo_dependencia_EM                            0\n",
      "descripcion_rama_educacional_EM                        0\n",
      "numero_estado_civil                                    0\n",
      "descripcion_trabajo_remunerado                         0\n",
      "numero_horario_trabajo                                 0\n",
      "descripcion_proseguir_estudios                         0\n",
      "descripcion_fuente_financiamiento_estudio_superior     0\n",
      "descripcion_fuente_financiamiento_estudio_superior2    0\n",
      "inferior_ingreso_bruto_fam                             0\n",
      "superior_ingreso_bruto_fam                             0\n",
      "nombre_cobertura_salud                                 0\n",
      "descripcion_viven_padres                               0\n",
      "descripcion_situacion_ocupacional_padre                0\n",
      "descripcion_situacion_ocupacional_madre                0\n",
      "horas_promedio_trabajo                                 0\n",
      "cantidad_personas_grupo_familiar                       0\n",
      "cuantos_estudian_grupo_superior                        0\n",
      "ptje_nem                                               0\n",
      "ptje_leng                                              0\n",
      "ptje_mate                                              0\n",
      "ptje_hycs                                              0\n",
      "ptje_cien                                              0\n",
      "Rotulo_Titulo                                          0\n",
      "dtype: int64\n",
      "Valores únicos en 'Rotulo_Titulo': [1 0]\n",
      "Preprocesamiento completo y datos guardados en 'datos_preprocesados.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Ver el número de valores faltantes por columna\n",
    "valores_faltantes = datos.isnull().sum()\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(valores_faltantes)\n",
    "\n",
    "# Renombrar la columna 'Rotulo_Titulado' a 'Rotulo_Titulo' si es necesario\n",
    "if 'Rotulo_Titulado' in datos.columns:\n",
    "    datos = datos.rename(columns={'Rotulo_Titulado': 'Rotulo_Titulo'})\n",
    "\n",
    "# Verificar si la columna 'Rotulo_Titulo' existe\n",
    "if 'Rotulo_Titulo' not in datos.columns:\n",
    "    raise ValueError(\"La columna 'Rotulo_Titulo' no se encuentra en el conjunto de datos.\")\n",
    "\n",
    "# Codificar la columna objetivo (si es necesario)\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Verificar los valores únicos en la columna objetivo\n",
    "print(\"Valores únicos en 'Rotulo_Titulo':\", datos['Rotulo_Titulo'].unique())\n",
    "\n",
    "# Identificar las columnas categóricas\n",
    "columnas_categoricas = datos.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Codificar las variables categóricas\n",
    "datos_codificados = pd.get_dummies(datos, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "# Normalizar las características numéricas\n",
    "columnas_numericas = datos_codificados.select_dtypes(include=['float64', 'int64']).columns\n",
    "escalador = StandardScaler()\n",
    "datos_codificados[columnas_numericas] = escalador.fit_transform(datos_codificados[columnas_numericas])\n",
    "\n",
    "# Guardar los datos preprocesados para la siguiente actividad\n",
    "datos_codificados.to_csv('datos_preprocesados.csv', index=False)\n",
    "\n",
    "print(\"Preprocesamiento completo y datos guardados en 'datos_preprocesados.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos únicos en 'Rotulo_Titulo': [ 0 -1]\n",
      "Pliegue 1: Tamaño de entrenamiento = 2414, Tamaño de validación = 604\n",
      "Pliegue 2: Tamaño de entrenamiento = 2414, Tamaño de validación = 604\n",
      "Pliegue 3: Tamaño de entrenamiento = 2414, Tamaño de validación = 604\n",
      "Pliegue 4: Tamaño de entrenamiento = 2415, Tamaño de validación = 603\n",
      "Pliegue 5: Tamaño de entrenamiento = 2415, Tamaño de validación = 603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Cargar el conjunto de datos preprocesado\n",
    "archivo = 'datos_preprocesados.csv'\n",
    "datos = pd.read_csv(archivo)\n",
    "\n",
    "# Verificar y corregir la columna objetivo si es necesario\n",
    "if datos['Rotulo_Titulo'].dtype == object:\n",
    "    datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Asegurarse de que 'Rotulo_Titulo' sea de tipo entero\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].astype(int)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop('Rotulo_Titulo', axis=1)\n",
    "y = datos['Rotulo_Titulo']\n",
    "\n",
    "# Verificar nuevamente el tipo de y después de la codificación\n",
    "print(\"Tipos únicos en 'Rotulo_Titulo':\", y.unique())\n",
    "\n",
    "# Definir el número de pliegues para la validación cruzada\n",
    "num_pliegues = 5\n",
    "validacion_cruzada = StratifiedKFold(n_splits=num_pliegues, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterar sobre los pliegues\n",
    "for i, (train_index, val_index) in enumerate(validacion_cruzada.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Aquí puedes entrenar tu modelo usando X_train, y_train\n",
    "    # y evaluarlo usando X_val, y_val para cada pliegue\n",
    "    \n",
    "    print(f\"Pliegue {i+1}: Tamaño de entrenamiento = {len(train_index)}, Tamaño de validación = {len(val_index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Random Forest...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "90 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "78 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.74550866 0.75047665 0.74881827 0.74153076 0.75146838 0.7524656\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74384699 0.74617256 0.74152746 0.7402079  0.74086905 0.74551086\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74219575 0.74882047 0.75180444 0.7455136  0.74716868 0.74981879]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración encontrada: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Puntaje de validación cruzada: 0.7524655969600123\n",
      "\n",
      "Optimizando SVM...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cargar los datos preprocesados\n",
    "archivo = 'datos_preprocesados.csv'\n",
    "datos = pd.read_csv(archivo)\n",
    "\n",
    "# Verificar y corregir la columna objetivo si es necesario\n",
    "if datos['Rotulo_Titulo'].dtype == object:\n",
    "    datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Asegurarse de que 'Rotulo_Titulo' sea de tipo entero\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].astype(int)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop('Rotulo_Titulo', axis=1)\n",
    "y = datos['Rotulo_Titulo']\n",
    "\n",
    "# Definir los modelos y los hiperparámetros a ajustar\n",
    "modelos = {\n",
    "    'Random Forest': {\n",
    "        'modelo': RandomForestClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'modelo': SVC(),\n",
    "        'parametros': {\n",
    "            'C': [1, 10, 100],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'degree': [2, 3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros y seleccionar el mejor modelo para cada tipo\n",
    "mejores_modelos = {}\n",
    "for nombre, config in modelos.items():\n",
    "    print(f\"Optimizando {nombre}...\")\n",
    "    grid_search = GridSearchCV(config['modelo'], config['parametros'], cv=5, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    mejores_modelos[nombre] = grid_search.best_estimator_\n",
    "    print(f\"Mejor configuración encontrada: {grid_search.best_params_}\")\n",
    "    print(f\"Puntaje de validación cruzada: {grid_search.best_score_}\\n\")\n",
    "\n",
    "# Seleccionar el mejor modelo basado en los resultados de validación cruzada\n",
    "mejor_modelo = max(mejores_modelos, key=lambda x: grid_search.best_score_)\n",
    "print(f\"El mejor modelo encontrado es: {mejor_modelo}\")\n",
    "print(f\"Con una precisión media de: {grid_search.best_score_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
