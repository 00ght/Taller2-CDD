{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna:\n",
      "Id                                                     0\n",
      "MAT_1SEM_PROM                                          0\n",
      "FIS_1SEM_PROM                                          0\n",
      "ING_1SEM_PROM                                          0\n",
      "ACTF_1SEM_A                                            0\n",
      "OTRANS_1SEM_A                                          0\n",
      "OTRANS_1SEM_R                                          0\n",
      "OTRANS_1SEM_PROM                                       0\n",
      "ESP_1SEM_A                                             0\n",
      "ESP_1SEM_R                                             0\n",
      "ESP_1SEM_PROM                                          0\n",
      "INS_1SEM                                               0\n",
      "PROM_1SEM                                              0\n",
      "MAT_2SEM_PROM                                          0\n",
      "FIS_2SEM_PROM                                          0\n",
      "ING_2SEM_PROM                                          0\n",
      "ACTF_2SEM_A                                            0\n",
      "OTRANS_2SEM_A                                          0\n",
      "OTRANS_2SEM_R                                          0\n",
      "OTRANS_2SEM_PROM                                       0\n",
      "ESP_2SEM_A                                             0\n",
      "ESP_2SEM_R                                             0\n",
      "ESP_2SEM_PROM                                          0\n",
      "INS_2SEM                                               0\n",
      "PROM_2SEM                                              0\n",
      "INSC_AnO                                               0\n",
      "PROM_AnO                                               0\n",
      "GENERO                                                 0\n",
      "NOM_CARRERA                                            0\n",
      "TIPO_CARRERA                                           0\n",
      "nombre_nacionalidad                                    0\n",
      "nombre_comuna_EM                                       0\n",
      "nombre_provincia_EM                                    0\n",
      "nombre_region_EM                                       0\n",
      "nombre_grupo_dependencia_EM                            0\n",
      "descripcion_rama_educacional_EM                        0\n",
      "numero_estado_civil                                    0\n",
      "descripcion_trabajo_remunerado                         0\n",
      "numero_horario_trabajo                                 0\n",
      "descripcion_proseguir_estudios                         0\n",
      "descripcion_fuente_financiamiento_estudio_superior     0\n",
      "descripcion_fuente_financiamiento_estudio_superior2    0\n",
      "inferior_ingreso_bruto_fam                             0\n",
      "superior_ingreso_bruto_fam                             0\n",
      "nombre_cobertura_salud                                 0\n",
      "descripcion_viven_padres                               0\n",
      "descripcion_situacion_ocupacional_padre                0\n",
      "descripcion_situacion_ocupacional_madre                0\n",
      "horas_promedio_trabajo                                 0\n",
      "cantidad_personas_grupo_familiar                       0\n",
      "cuantos_estudian_grupo_superior                        0\n",
      "ptje_nem                                               0\n",
      "ptje_leng                                              0\n",
      "ptje_mate                                              0\n",
      "ptje_hycs                                              0\n",
      "ptje_cien                                              0\n",
      "Rotulo_Titulo                                          0\n",
      "dtype: int64\n",
      "Valores únicos en 'Rotulo_Titulo': [1 0]\n",
      "Preprocesamiento completo y datos guardados en 'datos_preprocesados.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Ver el número de valores faltantes por columna\n",
    "valores_faltantes = datos.isnull().sum()\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(valores_faltantes)\n",
    "\n",
    "# Renombrar la columna 'Rotulo_Titulado' a 'Rotulo_Titulo' si es necesario\n",
    "if 'Rotulo_Titulado' in datos.columns:\n",
    "    datos = datos.rename(columns={'Rotulo_Titulado': 'Rotulo_Titulo'})\n",
    "\n",
    "# Verificar si la columna 'Rotulo_Titulo' existe\n",
    "if 'Rotulo_Titulo' not in datos.columns:\n",
    "    raise ValueError(\"La columna 'Rotulo_Titulo' no se encuentra en el conjunto de datos.\")\n",
    "\n",
    "# Codificar la columna objetivo (si es necesario)\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Verificar los valores únicos en la columna objetivo\n",
    "print(\"Valores únicos en 'Rotulo_Titulo':\", datos['Rotulo_Titulo'].unique())\n",
    "\n",
    "# Identificar las columnas categóricas\n",
    "columnas_categoricas = datos.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Codificar las variables categóricas\n",
    "datos_codificados = pd.get_dummies(datos, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "# Normalizar las características numéricas\n",
    "columnas_numericas = datos_codificados.select_dtypes(include=['float64', 'int64']).columns\n",
    "escalador = StandardScaler()\n",
    "datos_codificados[columnas_numericas] = escalador.fit_transform(datos_codificados[columnas_numericas])\n",
    "\n",
    "# Guardar los datos preprocesados para la siguiente actividad\n",
    "datos_codificados.to_csv('datos_preprocesados.csv', index=False)\n",
    "\n",
    "print(\"Preprocesamiento completo y datos guardados en 'datos_preprocesados.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos únicos en 'Rotulo_Titulo': [ 0 -1]\n",
      "Pliegue 1: Tamaño de entrenamiento = 2414, Tamaño de validación = 604\n",
      "Pliegue 2: Tamaño de entrenamiento = 2414, Tamaño de validación = 604\n",
      "Pliegue 3: Tamaño de entrenamiento = 2414, Tamaño de validación = 604\n",
      "Pliegue 4: Tamaño de entrenamiento = 2415, Tamaño de validación = 603\n",
      "Pliegue 5: Tamaño de entrenamiento = 2415, Tamaño de validación = 603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Cargar el conjunto de datos preprocesado\n",
    "archivo = 'datos_preprocesados.csv'\n",
    "datos = pd.read_csv(archivo)\n",
    "\n",
    "# Verificar y corregir la columna objetivo si es necesario\n",
    "if datos['Rotulo_Titulo'].dtype == object:\n",
    "    datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Asegurarse de que 'Rotulo_Titulo' sea de tipo entero\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].astype(int)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop('Rotulo_Titulo', axis=1)\n",
    "y = datos['Rotulo_Titulo']\n",
    "\n",
    "# Verificar nuevamente el tipo de y después de la codificación\n",
    "print(\"Tipos únicos en 'Rotulo_Titulo':\", y.unique())\n",
    "\n",
    "# Definir el número de pliegues para la validación cruzada\n",
    "num_pliegues = 5\n",
    "validacion_cruzada = StratifiedKFold(n_splits=num_pliegues, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterar sobre los pliegues\n",
    "for i, (train_index, val_index) in enumerate(validacion_cruzada.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Aquí puedes entrenar tu modelo usando X_train, y_train\n",
    "    # y evaluarlo usando X_val, y_val para cada pliegue\n",
    "    \n",
    "    print(f\"Pliegue {i+1}: Tamaño de entrenamiento = {len(train_index)}, Tamaño de validación = {len(val_index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizando Random Forest...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "90 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "78 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.74550866 0.75047665 0.74881827 0.74153076 0.75146838 0.7524656\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74384699 0.74617256 0.74152746 0.7402079  0.74086905 0.74551086\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74219575 0.74882047 0.75180444 0.7455136  0.74716868 0.74981879]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración encontrada: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Puntaje de validación cruzada: 0.7524655969600123\n",
      "\n",
      "Optimizando SVM...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Mejor configuración encontrada: {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Puntaje de validación cruzada: 0.7465080777129803\n",
      "\n",
      "El mejor modelo encontrado es: Random Forest\n",
      "Con una precisión media de: 0.7465080777129803\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cargar los datos preprocesados\n",
    "archivo = 'datos_preprocesados.csv'\n",
    "datos = pd.read_csv(archivo)\n",
    "\n",
    "# Verificar y corregir la columna objetivo si es necesario\n",
    "if datos['Rotulo_Titulo'].dtype == object:\n",
    "    datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Asegurarse de que 'Rotulo_Titulo' sea de tipo entero\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].astype(int)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop('Rotulo_Titulo', axis=1)\n",
    "y = datos['Rotulo_Titulo']\n",
    "\n",
    "# Definir los hiperparámetros para SVM\n",
    "parametros_svm = {\n",
    "    'C': [1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3]\n",
    "}\n",
    "\n",
    "# Crear el modelo de SVM\n",
    "modelo_svm = SVC()\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros para SVM\n",
    "grid_search_svm = GridSearchCV(modelo_svm, parametros_svm, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search_svm.fit(X, y)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Mejor configuración encontrada para SVM:\")\n",
    "print(grid_search_svm.best_params_)\n",
    "print(\"Puntaje de validación cruzada:\")\n",
    "print(grid_search_svm.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Mejor configuración encontrada para Random Forest:\n",
      "{'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Puntaje de validación cruzada:\n",
      "0.7557790517610623\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cargar los datos preprocesados\n",
    "archivo = 'datos_preprocesados.csv'\n",
    "datos = pd.read_csv(archivo)\n",
    "\n",
    "# Verificar y corregir la columna objetivo si es necesario\n",
    "if datos['Rotulo_Titulo'].dtype == object:\n",
    "    datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Asegurarse de que 'Rotulo_Titulo' sea de tipo entero\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].astype(int)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop('Rotulo_Titulo', axis=1)\n",
    "y = datos['Rotulo_Titulo']\n",
    "\n",
    "# Definir los hiperparámetros para Random Forest\n",
    "parametros_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Crear el modelo de Random Forest\n",
    "modelo_rf = RandomForestClassifier()\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros para Random Forest\n",
    "grid_search_rf = GridSearchCV(modelo_rf, parametros_rf, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search_rf.fit(X, y)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Mejor configuración encontrada para Random Forest:\")\n",
    "print(grid_search_rf.best_params_)\n",
    "print(\"Puntaje de validación cruzada:\")\n",
    "print(grid_search_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "archivo = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "# Ver el número de valores faltantes por columna\n",
    "valores_faltantes = datos.isnull().sum()\n",
    "print(\"Valores faltantes por columna:\")\n",
    "print(valores_faltantes)\n",
    "\n",
    "# Renombrar la columna 'Rotulo_Titulado' a 'Rotulo_Titulo' si es necesario\n",
    "if 'Rotulo_Titulado' in datos.columns:\n",
    "    datos = datos.rename(columns={'Rotulo_Titulado': 'Rotulo_Titulo'})\n",
    "\n",
    "# Verificar si la columna 'Rotulo_Titulo' existe\n",
    "if 'Rotulo_Titulo' not in datos.columns:\n",
    "    raise ValueError(\"La columna 'Rotulo_Titulo' no se encuentra en el conjunto de datos.\")\n",
    "\n",
    "# Codificar la columna objetivo (si es necesario)\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Verificar los valores únicos en la columna objetivo\n",
    "print(\"Valores únicos en 'Rotulo_Titulo':\", datos['Rotulo_Titulo'].unique())\n",
    "\n",
    "# Identificar las columnas categóricas\n",
    "columnas_categoricas = datos.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Codificar las variables categóricas\n",
    "datos_codificados = pd.get_dummies(datos, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "# Normalizar las características numéricas\n",
    "columnas_numericas = datos_codificados.select_dtypes(include=['float64', 'int64']).columns\n",
    "escalador = StandardScaler()\n",
    "datos_codificados[columnas_numericas] = escalador.fit_transform(datos_codificados[columnas_numericas])\n",
    "\n",
    "# Guardar los datos preprocesados para la siguiente actividad\n",
    "datos_codificados.to_csv('datos_preprocesados.csv', index=False)\n",
    "\n",
    "print(\"Preprocesamiento completo y datos guardados en 'datos_preprocesados.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Cargar el conjunto de datos preprocesado\n",
    "archivo = 'datosEvaluacion_preprocesados.csv'\n",
    "datos = pd.read_csv(archivo)\n",
    "\n",
    "# Verificar y corregir la columna objetivo si es necesario\n",
    "if datos['Rotulo_Titulo'].dtype == object:\n",
    "    datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].apply(lambda x: 1 if x == 'SI' else 0)\n",
    "\n",
    "# Asegurarse de que 'Rotulo_Titulo' sea de tipo entero\n",
    "datos['Rotulo_Titulo'] = datos['Rotulo_Titulo'].astype(int)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos.drop('Rotulo_Titulo', axis=1)\n",
    "y = datos['Rotulo_Titulo']\n",
    "\n",
    "# Verificar nuevamente el tipo de y después de la codificación\n",
    "print(\"Tipos únicos en 'Rotulo_Titulo':\", y.unique())\n",
    "\n",
    "# Definir el número de pliegues para la validación cruzada\n",
    "num_pliegues = 5\n",
    "validacion_cruzada = StratifiedKFold(n_splits=num_pliegues, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterar sobre los pliegues\n",
    "for i, (train_index, val_index) in enumerate(validacion_cruzada.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Aquí puedes entrenar tu modelo usando X_train, y_train\n",
    "    # y evaluarlo usando X_val, y_val para cada pliegue\n",
    "    \n",
    "    print(f\"Pliegue {i+1}: Tamaño de entrenamiento = {len(train_index)}, Tamaño de validación = {len(val_index)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Id', 'MAT_1SEM_PROM', 'FIS_1SEM_PROM', 'ING_1SEM_PROM', 'ACTF_1SEM_A',\\n       'OTRANS_1SEM_A', 'OTRANS_1SEM_R', 'OTRANS_1SEM_PROM', 'ESP_1SEM_A',\\n       'ESP_1SEM_R',\\n       ...\\n       'descripcion_situacion_ocupacional_padre_Otra situación',\\n       'descripcion_situacion_ocupacional_padre_Sin Datos',\\n       'descripcion_situacion_ocupacional_padre_Trabaja sólo ocasionalmente',\\n       'descripcion_situacion_ocupacional_madre_Cesante',\\n       'descripcion_situacion_ocupacional_madre_Dueno de casa',\\n       'descripcion_situacion_ocupacional_madre_Jubilado o pensionado (no reincorporado)',\\n       'descripcion_situacion_ocupacional_madre_No trabaja (enfermedad& edad avanzada)',\\n       'descripcion_situacion_ocupacional_madre_Otra situación',\\n       'descripcion_situacion_ocupacional_madre_Sin Datos',\\n       'descripcion_situacion_ocupacional_madre_Trabaja sólo ocasionalmente'],\\n      dtype='object', length=341)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Preprocesamiento similar al utilizado en el entrenamiento\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Asegúrate de aplicar las mismas transformaciones que en los datos de entrenamiento\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Aquí deberías tener el mismo código de preprocesamiento que usaste antes del ajuste del modelo\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Ajustar las columnas de los datos de evaluación si es necesario\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Verificar y eliminar columnas adicionales que no se usaron en el entrenamiento\u001b[39;00m\n\u001b[0;32m     17\u001b[0m columnas_entrenamiento \u001b[38;5;241m=\u001b[39m X_entrenamiento\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 18\u001b[0m datos_evaluacion \u001b[38;5;241m=\u001b[39m \u001b[43mdatos_evaluacion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumnas_entrenamiento\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Suponiendo que ya tienes cargado y ajustado el mejor modelo de la Actividad 3\u001b[39;00m\n\u001b[0;32m     21\u001b[0m mejor_modelo \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vania\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Id', 'MAT_1SEM_PROM', 'FIS_1SEM_PROM', 'ING_1SEM_PROM', 'ACTF_1SEM_A',\\n       'OTRANS_1SEM_A', 'OTRANS_1SEM_R', 'OTRANS_1SEM_PROM', 'ESP_1SEM_A',\\n       'ESP_1SEM_R',\\n       ...\\n       'descripcion_situacion_ocupacional_padre_Otra situación',\\n       'descripcion_situacion_ocupacional_padre_Sin Datos',\\n       'descripcion_situacion_ocupacional_padre_Trabaja sólo ocasionalmente',\\n       'descripcion_situacion_ocupacional_madre_Cesante',\\n       'descripcion_situacion_ocupacional_madre_Dueno de casa',\\n       'descripcion_situacion_ocupacional_madre_Jubilado o pensionado (no reincorporado)',\\n       'descripcion_situacion_ocupacional_madre_No trabaja (enfermedad& edad avanzada)',\\n       'descripcion_situacion_ocupacional_madre_Otra situación',\\n       'descripcion_situacion_ocupacional_madre_Sin Datos',\\n       'descripcion_situacion_ocupacional_madre_Trabaja sólo ocasionalmente'],\\n      dtype='object', length=341)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el conjunto de datos de evaluación\n",
    "\n",
    "archivo_evaluacion = 'Taller_2_Titulacion_DatosTaller.csv'\n",
    "datos_evaluacion = pd.read_csv(archivo, encoding='latin-1', delimiter=';')\n",
    "\n",
    "\n",
    "# Preprocesamiento similar al utilizado en el entrenamiento\n",
    "# Asegúrate de aplicar las mismas transformaciones que en los datos de entrenamiento\n",
    "# Aquí deberías tener el mismo código de preprocesamiento que usaste antes del ajuste del modelo\n",
    "\n",
    "# Ajustar las columnas de los datos de evaluación si es necesario\n",
    "# Verificar y eliminar columnas adicionales que no se usaron en el entrenamiento\n",
    "columnas_entrenamiento = X_entrenamiento.columns.tolist()\n",
    "datos_evaluacion = datos_evaluacion[columnas_entrenamiento]\n",
    "\n",
    "# Suponiendo que ya tienes cargado y ajustado el mejor modelo de la Actividad 3\n",
    "mejor_modelo = RandomForestClassifier(n_estimators=150, max_depth=None, min_samples_split=5, max_features='sqrt')\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "X_entrenamiento = datos.drop('Rotulo_Titulo', axis=1)  # Ajusta según tus datos de entrenamiento\n",
    "y_entrenamiento = datos['Rotulo_Titulo']  # Ajusta según tus datos de entrenamiento\n",
    "mejor_modelo.fit(X_entrenamiento, y_entrenamiento)\n",
    "\n",
    "# Preprocesar los datos de evaluación de la misma manera que los datos de entrenamiento\n",
    "# Esto puede incluir codificación de variables categóricas, normalización, etc.\n",
    "# Asegúrate de aplicar cualquier transformación que hayas hecho en los datos de entrenamiento\n",
    "\n",
    "# Hacer predicciones sobre los datos de evaluación\n",
    "predicciones = mejor_modelo.predict(datos_evaluacion)\n",
    "\n",
    "# Crear un DataFrame con los resultados de predicción\n",
    "resultados = pd.DataFrame({\n",
    "    'Id': datos_evaluacion['Id'],  # Ajusta según la columna de identificación en tus datos de evaluación\n",
    "    'Prediccion': predicciones  # Debe contener 'SI' o 'NO' según lo definido en tu modelo\n",
    "})\n",
    "\n",
    "# Generar el archivo de salida en formato txt\n",
    "archivo_salida = 'clasificacion_titulo4.txt'\n",
    "resultados.to_csv(archivo_salida, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(f\"Archivo '{archivo_salida}' generado exitosamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
